{"componentChunkName":"component---src-pages-upgrade-configuration-mdx","path":"/upgrade/configuration/","result":{"pageContext":{"frontmatter":{"title":"Configuration"},"relativePagePath":"/upgrade/configuration.mdx","titleType":"append","MdxNode":{"id":"ee7227f4-37f7-57de-b941-47ab55514e62","children":[],"parent":"62935a5c-69e2-545d-8b9b-1d36bde3acb3","internal":{"content":"---\ntitle: Configuration\n---           \n\n## Deployment Configuration\n\nWhen the Manage application is deployed in MAS, a Manage deployment CR is created.\n- The Manage deployment CR contains the configuration entered by the user including database URL, server bundle types, deployment sizing etc. \n- The database username/password can be specified from the MAS UI and persisted as a Secret in the cluster. \n- The Manage crypto/cryptox properties can be updated from the MAS UI and persisted as a Secret in the cluster. \n- Both Secrets (username/password, crypto/cryptox) can also be updated from OpenShift CLI. Any change to the values will automatically redeploy (complete/partial) the application.\n\n\n## Server Bundle\n\nA server bundle (workload) is a logical abstraction for a deployed group of PODs(Point of deployment) in a cluster to perform the same function and provides an access point as a service. These can be accessed as a service internally and through a route externally (a route is a way to expose a service by giving externally-reachable hostname). Through route or service, OpenShift provides load balancing to the PODS included in a server bundle. Each server bundle defines replica size, subdomain, etc.\n\n- For each server bundle, a service is screated with name appended by -&ltserverbundlename&gt.\n- A route is created with name appended by -&ltserverbundlename&gt.\n- A default route will be created to point to the service ending with -&ltserverbundlename&gt.\n  - The default route is used by MAS UI to establish the default URL link to the Manage application.\n  \n\nThe following diagram illustrates OpenShift Container Platform routers provide external host name mapping and load balancing of service end points over protocols. The router uses the hostname to determine where to send the external client request.\n\n![image](images/services.png)\n\n\n<p></p>\n\n- The Manage application can be deployed with different server bundles (workloads) for the processing and isolation needs. \n- The deployment can be 'All' bundle server type only or a combination of four bundle server types (UI, Cron, Report, MEA).\n  - If \"All\" bundle server type is not deployed, and you used a combination of the four bundle server types, the \"UI\" bundle server type is required.\n- Each server bundle can have its own server properties.\n\nThis table below shows the five different server bundles types:\n\n<table>\n\n  <tr>\n    <th>Bundle Server Type</th><th>Description</th>\n  </tr>\n\n  <tr>\n    <td>All</td>\n    <td>This bundle type contains all the code.</td>\n  </tr>\n\n\n  <tr>\n    <td>UI</td>\n    <td>This bundle type contains UI code and supporting code. It is the interface for accessing Manage application.</td>\n  </tr>\n\n\n   <tr>\n    <td>MEA</td>\n    <td>This bundle exposes the enterprise web services API. </td>\n   </tr>\n\n   <tr>\n    <td>Report</td>\n    <td>This bundle contains the code that is needed to enable BIRT Report Only Server (BROS). Used to separate out the work load that is related to execution of reports that are submitted from the Manage UI. </td>\n   </tr>\n\n   <tr>\n    <td>Cron</td>\n    <td>This bundle contains the code that is needed to run Manage cron tasks.</td>\n   </tr>\n \n</table>\n\n\n### Server Bundle Properties\n\n- The bundle properties can be added or updated for an individual server bundle from the MAS UI or directly by adding properties to the ConfigMap that referenced by the Manage Custom Resource(CR).\n- The ConfigMap will be mapped as the bundle.properties in the Manage pods. \n   - The bundle.properties can be viewed from the OpenShift console from the pod in the terminal tab. It will be in \"/config/manage/properties\" directory after deployment.\n- If you need to define a new custom property as a bundle specific property, add the custom property to Manage by using the System Properties application before specifying it as a server bundle property. \n\nSample data section for ConfigMap:\n\n```\ndata:\n  bundle.properties:  |\n    mxe.crontask.donotrun=ALL \n    mxe.adminEmail=test@ibm.com\n```\n- The ConfigMap file can be deployed through OpenShift UI or manually by adding \"bundleLevelProperties\" property in the deployment CR.\n- If you have created a new config map, it can be manually deployed by updating the \"bundleLevelProperties\" property in the deployment CR. Sample deployment CR snippet:\n\n```\nServerBundles:\n    - name: \"myuiservers\"\n      replica: 3 \n      isDefault: true\n      bundleType: ui\n      routeSubDomain: generic1\n      bundleLevelProperties: bundlepropertiesconfigmap\n      additionalServerConfig: serverxmlconfigmap   \n``` \n\n## Liberty Server XML\n\n- If you need to customize Liberty server.xml:\n   - You need to provide a ConfigMap file to include your custom configuration. See below a sample ConfigMap data section for server-custom.xml to enable JMS queues(serverxmlconfigmap.yml).   \n   - The content of the ConfigMap needs to follow the Liberty documentation of additional configuration files that can be included in the server.xml.\n   - The ConfigMap file can be deployed through OpenShift UI or manually by adding \"additionalServerConfig\" property in the deployment CR.\n   - The ConfigMap will be mapped as the server-custom.xml in the manage pods. It will be included in the server.xml as the additional configuration. \n     - The server-custom.xml can be viewed from the OpenShift console from the pod in the terminal tab. It will be in \"/config/manage/serverxml\" folder after deployment.\n   \n   \n```\ndata:\n  server-custom.xml:  |\n\t<logging traceSpecification=\"JMSApi=all:WAS.j2c=all\"/> \n\t<variable name=\"wmqJmsClient.rar.location\" value=\"${wlp.install.dir}/../wmq/wmq.jmsra.rar\"/>\n\t<!--containerAuthData id=\"auth1\" user=\"maximomif\" password=\"xxxx\"/-->\n\t\n\t\t<jmsConnectionFactory jndiName=\"jms/maximo/int/cf/intcf\" connectionManagerRef=\"MIFJMS\">\n\t\t\t<properties.wmqJms \n\t\t\t    transportType=\"CLIENT\"\n\t\t\t    hostName=\"libertymanager-c553.qm.us-south.mq.appdomain.cloud\" \n\t\t\t    port=\"30216\"\n\t\t\t    channel=\"CLOUD.APP.SVRCONN\"\n\t\t\t    applicationName=\"maxliberty\"\n\t\t\t    userName=\"xxx\"\n\t\t\t    password=\"xxxxx\"\n\t\t\t    queueManager=\"LIBERTYMANAGER\"/>\n\t       \t</jmsConnectionFactory>\n\t\t<connectionManager id=\"MIFJMS\" maxPoolSize=\"20\"/>\n\t\t<jmsQueue id=\"sqout\" jndiName=\"jms/maximo/int/queues/sqout\">\n\t\t\t<properties.wmqJms baseQueueName=\"sqout\" baseQueueManagerName=\"LIBERTYMANAGER\"/>\n    \t\t</jmsQueue>\n\t\t<jmsQueue id=\"sqin\" jndiName=\"jms/maximo/int/queues/sqin\">\n      \t\t\t<properties.wmqJms baseQueueName=\"sqin\" baseQueueManagerName=\"LIBERTYMANAGER\"/>\n    \t\t</jmsQueue>\n\t\t<jmsQueue id=\"jms/maximo/int/queues/cqin\" jndiName=\"jms/maximo/int/queues/cqin\">\n      \t\t\t<properties.wmqJms baseQueueName=\"cqin\" baseQueueManagerName=\"LIBERTYMANAGER\"/>\n    \t\t</jmsQueue>\n\t\t<jmsQueue id=\"jms/maximo/int/queues/cqinerr\" jndiName=\"jms/maximo/int/queues/cqinerr\">\n      \t\t\t<properties.wmqJms baseQueueName=\"cqinerr\" baseQueueManagerName=\"LIBERTYMANAGER\"/>\n   \t\t</jmsQueue>\n\t\t<jmsActivationSpec id=\"maximomea/mboejb/JMSContQueueProcessor-1\">\n\t\t\t<properties.wmqJms\n\t\t\t   transportType=\"CLIENT\"\n\t\t\t   destinationRef=\"jms/maximo/int/queues/cqin\"\n\t\t\t   destinationType=\"javax.jms.Queue\"\n\t\t           hostName=\"libertymanager-c553.qm.us-south.mq.appdomain.cloud\"\n\t\t\t   port=\"30216\"\n\t\t\t   maxSequentialDeliveryFailures=\"-1\"\n\t\t\t   channel=\"CLOUD.APP.SVRCONN\"\n\t\t\t   queueManager=\"LIBERTYMANAGER\"/>\n\t\t<authData id=\"auth1\" user=\"xxx\" password=\"xxx\"/>\n\t\t</jmsActivationSpec>\n\t\t\t<jmsActivationSpec id=\"maximomea/mboejb/JMSContQueueProcessor-2\">\n\t\t<properties.wmqJms\n\t\t\ttransportType=\"CLIENT\"\n\t\t\t   destinationRef=\"jms/maximo/int/queues/cqinerr\"\n\t\t\t   destinationType=\"javax.jms.Queue\"\n\t\t\t   hostName=\"libertymanager-c553.qm.us-south.mq.appdomain.cloud\"\n\t\t\t   port=\"30216\"\n\t\t\t   maxPoolDepth=\"1\"\n\t\t\t   maxSequentialDeliveryFailures=\"-1\"\n\t\t\t   channel=\"CLOUD.APP.SVRCONN\"\n\t\t\t   queueManager=\"LIBERTYMANAGER\"/>\n\t\t<authData id=\"auth1\" user=\"xxx\" password=\"xxx\"/>\n\t</jmsActivationSpec>\n</server>\n```\n\n- The ConfigMap file can be deployed through OpenShift UI or manually by adding \"additionalServerConfig\" property in the deployment CR.\n- If you have created a new config map, it can be manually deployed by updating the \"additionalServerConfig\" property in the deployment CR. Sample deployment CR snippet:\n\n```\nServerBundles:\n    - name: \"myuiservers\"\n      replica: 3\n      isDefault: true\n      bundleType: ui\n      routeSubDomain: generic1\n      additionalServerConfig: serverxmlconfigmap   \n``` \n\n\n\n## Attached Docs\n\n### If you using object storage: \n- No change needed. \n\n### If you are using the file system such as NFS:      \n- The persistent storage (specifically storage software and deployments, storage provisioner, storage classes, and persistent volumes) need to be setup. \n- You need to specify the required storage configuration (volume name, storage class, size, and mount path) from MAS UI (or CR) during the application deployment.\n- The Manage provides a Persistent Claim to claim this storage configuration and setup shared folders inside Manage pods accordingly.  \n- You can set up the same mount path as the doclinks directory you have in your current system and no configuration change will be needed for the doclinks configuration. If you have a different mount path, then the doclinks configuration needs to be updated to point to the new path. \n\n\n","type":"Mdx","contentDigest":"ab2f383f19ce8dc4adcc9a513db9394f","counter":122,"owner":"gatsby-plugin-mdx"},"frontmatter":{"title":"Configuration"},"exports":{},"rawBody":"---\ntitle: Configuration\n---           \n\n## Deployment Configuration\n\nWhen the Manage application is deployed in MAS, a Manage deployment CR is created.\n- The Manage deployment CR contains the configuration entered by the user including database URL, server bundle types, deployment sizing etc. \n- The database username/password can be specified from the MAS UI and persisted as a Secret in the cluster. \n- The Manage crypto/cryptox properties can be updated from the MAS UI and persisted as a Secret in the cluster. \n- Both Secrets (username/password, crypto/cryptox) can also be updated from OpenShift CLI. Any change to the values will automatically redeploy (complete/partial) the application.\n\n\n## Server Bundle\n\nA server bundle (workload) is a logical abstraction for a deployed group of PODs(Point of deployment) in a cluster to perform the same function and provides an access point as a service. These can be accessed as a service internally and through a route externally (a route is a way to expose a service by giving externally-reachable hostname). Through route or service, OpenShift provides load balancing to the PODS included in a server bundle. Each server bundle defines replica size, subdomain, etc.\n\n- For each server bundle, a service is screated with name appended by -&ltserverbundlename&gt.\n- A route is created with name appended by -&ltserverbundlename&gt.\n- A default route will be created to point to the service ending with -&ltserverbundlename&gt.\n  - The default route is used by MAS UI to establish the default URL link to the Manage application.\n  \n\nThe following diagram illustrates OpenShift Container Platform routers provide external host name mapping and load balancing of service end points over protocols. The router uses the hostname to determine where to send the external client request.\n\n![image](images/services.png)\n\n\n<p></p>\n\n- The Manage application can be deployed with different server bundles (workloads) for the processing and isolation needs. \n- The deployment can be 'All' bundle server type only or a combination of four bundle server types (UI, Cron, Report, MEA).\n  - If \"All\" bundle server type is not deployed, and you used a combination of the four bundle server types, the \"UI\" bundle server type is required.\n- Each server bundle can have its own server properties.\n\nThis table below shows the five different server bundles types:\n\n<table>\n\n  <tr>\n    <th>Bundle Server Type</th><th>Description</th>\n  </tr>\n\n  <tr>\n    <td>All</td>\n    <td>This bundle type contains all the code.</td>\n  </tr>\n\n\n  <tr>\n    <td>UI</td>\n    <td>This bundle type contains UI code and supporting code. It is the interface for accessing Manage application.</td>\n  </tr>\n\n\n   <tr>\n    <td>MEA</td>\n    <td>This bundle exposes the enterprise web services API. </td>\n   </tr>\n\n   <tr>\n    <td>Report</td>\n    <td>This bundle contains the code that is needed to enable BIRT Report Only Server (BROS). Used to separate out the work load that is related to execution of reports that are submitted from the Manage UI. </td>\n   </tr>\n\n   <tr>\n    <td>Cron</td>\n    <td>This bundle contains the code that is needed to run Manage cron tasks.</td>\n   </tr>\n \n</table>\n\n\n### Server Bundle Properties\n\n- The bundle properties can be added or updated for an individual server bundle from the MAS UI or directly by adding properties to the ConfigMap that referenced by the Manage Custom Resource(CR).\n- The ConfigMap will be mapped as the bundle.properties in the Manage pods. \n   - The bundle.properties can be viewed from the OpenShift console from the pod in the terminal tab. It will be in \"/config/manage/properties\" directory after deployment.\n- If you need to define a new custom property as a bundle specific property, add the custom property to Manage by using the System Properties application before specifying it as a server bundle property. \n\nSample data section for ConfigMap:\n\n```\ndata:\n  bundle.properties:  |\n    mxe.crontask.donotrun=ALL \n    mxe.adminEmail=test@ibm.com\n```\n- The ConfigMap file can be deployed through OpenShift UI or manually by adding \"bundleLevelProperties\" property in the deployment CR.\n- If you have created a new config map, it can be manually deployed by updating the \"bundleLevelProperties\" property in the deployment CR. Sample deployment CR snippet:\n\n```\nServerBundles:\n    - name: \"myuiservers\"\n      replica: 3 \n      isDefault: true\n      bundleType: ui\n      routeSubDomain: generic1\n      bundleLevelProperties: bundlepropertiesconfigmap\n      additionalServerConfig: serverxmlconfigmap   \n``` \n\n## Liberty Server XML\n\n- If you need to customize Liberty server.xml:\n   - You need to provide a ConfigMap file to include your custom configuration. See below a sample ConfigMap data section for server-custom.xml to enable JMS queues(serverxmlconfigmap.yml).   \n   - The content of the ConfigMap needs to follow the Liberty documentation of additional configuration files that can be included in the server.xml.\n   - The ConfigMap file can be deployed through OpenShift UI or manually by adding \"additionalServerConfig\" property in the deployment CR.\n   - The ConfigMap will be mapped as the server-custom.xml in the manage pods. It will be included in the server.xml as the additional configuration. \n     - The server-custom.xml can be viewed from the OpenShift console from the pod in the terminal tab. It will be in \"/config/manage/serverxml\" folder after deployment.\n   \n   \n```\ndata:\n  server-custom.xml:  |\n\t<logging traceSpecification=\"JMSApi=all:WAS.j2c=all\"/> \n\t<variable name=\"wmqJmsClient.rar.location\" value=\"${wlp.install.dir}/../wmq/wmq.jmsra.rar\"/>\n\t<!--containerAuthData id=\"auth1\" user=\"maximomif\" password=\"xxxx\"/-->\n\t\n\t\t<jmsConnectionFactory jndiName=\"jms/maximo/int/cf/intcf\" connectionManagerRef=\"MIFJMS\">\n\t\t\t<properties.wmqJms \n\t\t\t    transportType=\"CLIENT\"\n\t\t\t    hostName=\"libertymanager-c553.qm.us-south.mq.appdomain.cloud\" \n\t\t\t    port=\"30216\"\n\t\t\t    channel=\"CLOUD.APP.SVRCONN\"\n\t\t\t    applicationName=\"maxliberty\"\n\t\t\t    userName=\"xxx\"\n\t\t\t    password=\"xxxxx\"\n\t\t\t    queueManager=\"LIBERTYMANAGER\"/>\n\t       \t</jmsConnectionFactory>\n\t\t<connectionManager id=\"MIFJMS\" maxPoolSize=\"20\"/>\n\t\t<jmsQueue id=\"sqout\" jndiName=\"jms/maximo/int/queues/sqout\">\n\t\t\t<properties.wmqJms baseQueueName=\"sqout\" baseQueueManagerName=\"LIBERTYMANAGER\"/>\n    \t\t</jmsQueue>\n\t\t<jmsQueue id=\"sqin\" jndiName=\"jms/maximo/int/queues/sqin\">\n      \t\t\t<properties.wmqJms baseQueueName=\"sqin\" baseQueueManagerName=\"LIBERTYMANAGER\"/>\n    \t\t</jmsQueue>\n\t\t<jmsQueue id=\"jms/maximo/int/queues/cqin\" jndiName=\"jms/maximo/int/queues/cqin\">\n      \t\t\t<properties.wmqJms baseQueueName=\"cqin\" baseQueueManagerName=\"LIBERTYMANAGER\"/>\n    \t\t</jmsQueue>\n\t\t<jmsQueue id=\"jms/maximo/int/queues/cqinerr\" jndiName=\"jms/maximo/int/queues/cqinerr\">\n      \t\t\t<properties.wmqJms baseQueueName=\"cqinerr\" baseQueueManagerName=\"LIBERTYMANAGER\"/>\n   \t\t</jmsQueue>\n\t\t<jmsActivationSpec id=\"maximomea/mboejb/JMSContQueueProcessor-1\">\n\t\t\t<properties.wmqJms\n\t\t\t   transportType=\"CLIENT\"\n\t\t\t   destinationRef=\"jms/maximo/int/queues/cqin\"\n\t\t\t   destinationType=\"javax.jms.Queue\"\n\t\t           hostName=\"libertymanager-c553.qm.us-south.mq.appdomain.cloud\"\n\t\t\t   port=\"30216\"\n\t\t\t   maxSequentialDeliveryFailures=\"-1\"\n\t\t\t   channel=\"CLOUD.APP.SVRCONN\"\n\t\t\t   queueManager=\"LIBERTYMANAGER\"/>\n\t\t<authData id=\"auth1\" user=\"xxx\" password=\"xxx\"/>\n\t\t</jmsActivationSpec>\n\t\t\t<jmsActivationSpec id=\"maximomea/mboejb/JMSContQueueProcessor-2\">\n\t\t<properties.wmqJms\n\t\t\ttransportType=\"CLIENT\"\n\t\t\t   destinationRef=\"jms/maximo/int/queues/cqinerr\"\n\t\t\t   destinationType=\"javax.jms.Queue\"\n\t\t\t   hostName=\"libertymanager-c553.qm.us-south.mq.appdomain.cloud\"\n\t\t\t   port=\"30216\"\n\t\t\t   maxPoolDepth=\"1\"\n\t\t\t   maxSequentialDeliveryFailures=\"-1\"\n\t\t\t   channel=\"CLOUD.APP.SVRCONN\"\n\t\t\t   queueManager=\"LIBERTYMANAGER\"/>\n\t\t<authData id=\"auth1\" user=\"xxx\" password=\"xxx\"/>\n\t</jmsActivationSpec>\n</server>\n```\n\n- The ConfigMap file can be deployed through OpenShift UI or manually by adding \"additionalServerConfig\" property in the deployment CR.\n- If you have created a new config map, it can be manually deployed by updating the \"additionalServerConfig\" property in the deployment CR. Sample deployment CR snippet:\n\n```\nServerBundles:\n    - name: \"myuiservers\"\n      replica: 3\n      isDefault: true\n      bundleType: ui\n      routeSubDomain: generic1\n      additionalServerConfig: serverxmlconfigmap   \n``` \n\n\n\n## Attached Docs\n\n### If you using object storage: \n- No change needed. \n\n### If you are using the file system such as NFS:      \n- The persistent storage (specifically storage software and deployments, storage provisioner, storage classes, and persistent volumes) need to be setup. \n- You need to specify the required storage configuration (volume name, storage class, size, and mount path) from MAS UI (or CR) during the application deployment.\n- The Manage provides a Persistent Claim to claim this storage configuration and setup shared folders inside Manage pods accordingly.  \n- You can set up the same mount path as the doclinks directory you have in your current system and no configuration change will be needed for the doclinks configuration. If you have a different mount path, then the doclinks configuration needs to be updated to point to the new path. \n\n\n","fileAbsolutePath":"/home/travis/build/maximo/manage-playbook/src/pages/upgrade/configuration.mdx"}}},"staticQueryHashes":["1054721580","1054721580","1364590287","2102389209","2102389209","2456312558","2746626797","2746626797","3018647132","3018647132","3037994772","3037994772","768070550"]}