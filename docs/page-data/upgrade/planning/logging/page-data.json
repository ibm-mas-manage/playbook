{"componentChunkName":"component---src-pages-upgrade-planning-logging-mdx","path":"/upgrade/planning/logging/","result":{"pageContext":{"frontmatter":{"title":"Logging"},"relativePagePath":"/upgrade/planning/logging.mdx","titleType":"append","MdxNode":{"id":"644ef7cb-bcea-5306-8659-f48bed85fc53","children":[],"parent":"36daa18e-9328-5003-98a0-d5da19717c3b","internal":{"content":"---\ntitle: Logging\n---           \n\n## Manage Server Logs\n- Manage server logs are written to the standard output. You can view the logs from the OpenShift console. \n  - From the OpenShift console, go to the Workloads/Pods menu, select the pod for your project. Select the Logs tab to view logs.\n  - You can use \"Kubectl\" commands to view logs from a terminal.\n<p></p>\n- You can also configure MAS supported log configuration by OpenShift. For example, Elasticsearch, Fluentd, and Kibana dashboard (EFK) can be configured for Logging. The logs automatically flow to the EFK stack.\n  - Aggregated Manage logs can be retrieved from the EFK stack.\n<p></p>\n- You can also push the logs to Cloud Object Storage(COS) by following the steps below:\n  - Setup: \n    - Set up an S3 account.\n    - Create the following four environment variables in your Manage deployment:\n      - LOG_BUCKETNAME\n      - LOG_S3ACCESSKEY\n      - LOG_S3ENDPOINTURL\n        - For example: https://s3.us.cloud.object.storage.appdomain.cloud\n      - LOG_S3SECRETKEY\n  - Create a log request(POST) using any HTTP Rest Client. For example, the Postman tool.\n    - Request URL: http://manageserver:7001/maximo/oslc/service/logging?action=wsmethd:submitUploadRequest\n      - Replace the manageserver in the above URL to your manage server host or IP address.\n      - A record will be created in the Manage table(LOGREQUEST)\n   - Each  Manage server handles the latest log request. It will zip the logs in the liberty log directory and upload it in COS. \n   - You can use the S3 browser to view the logs using your S3 account credentials.\n   - The logs can be downloaded from the Liberty server. It will be in the directory that is set for the system property \"server.output.dir\".\n     - For example, \"/opt/was/libert/wip/usr/servers/default/\n     - A record will be created in the Manage table (LOGREQUESTDET)\n     - The Manage table records will be removed by cron task (LOGREQUESTCLEANUP) after posting logs to COS.\n       - The cron task needs to be activated manually. It will run once every day.\n   \n\n## Maxinst/Update Database Logs\n- The maxinst and update database logs can be retrieved from the admin console pod.\n  - From the OpenShift console, go to the Workloads/Pods menu, select the maxinst pod for your project. Go to terminal tab and cd \"/opt/IBM/SMP/maximo/tools/log/\"  directory to view logs. \n    ","type":"Mdx","contentDigest":"7addf96a86a0ce8d2619d6476be4ce75","counter":143,"owner":"gatsby-plugin-mdx"},"frontmatter":{"title":"Logging"},"exports":{},"rawBody":"---\ntitle: Logging\n---           \n\n## Manage Server Logs\n- Manage server logs are written to the standard output. You can view the logs from the OpenShift console. \n  - From the OpenShift console, go to the Workloads/Pods menu, select the pod for your project. Select the Logs tab to view logs.\n  - You can use \"Kubectl\" commands to view logs from a terminal.\n<p></p>\n- You can also configure MAS supported log configuration by OpenShift. For example, Elasticsearch, Fluentd, and Kibana dashboard (EFK) can be configured for Logging. The logs automatically flow to the EFK stack.\n  - Aggregated Manage logs can be retrieved from the EFK stack.\n<p></p>\n- You can also push the logs to Cloud Object Storage(COS) by following the steps below:\n  - Setup: \n    - Set up an S3 account.\n    - Create the following four environment variables in your Manage deployment:\n      - LOG_BUCKETNAME\n      - LOG_S3ACCESSKEY\n      - LOG_S3ENDPOINTURL\n        - For example: https://s3.us.cloud.object.storage.appdomain.cloud\n      - LOG_S3SECRETKEY\n  - Create a log request(POST) using any HTTP Rest Client. For example, the Postman tool.\n    - Request URL: http://manageserver:7001/maximo/oslc/service/logging?action=wsmethd:submitUploadRequest\n      - Replace the manageserver in the above URL to your manage server host or IP address.\n      - A record will be created in the Manage table(LOGREQUEST)\n   - Each  Manage server handles the latest log request. It will zip the logs in the liberty log directory and upload it in COS. \n   - You can use the S3 browser to view the logs using your S3 account credentials.\n   - The logs can be downloaded from the Liberty server. It will be in the directory that is set for the system property \"server.output.dir\".\n     - For example, \"/opt/was/libert/wip/usr/servers/default/\n     - A record will be created in the Manage table (LOGREQUESTDET)\n     - The Manage table records will be removed by cron task (LOGREQUESTCLEANUP) after posting logs to COS.\n       - The cron task needs to be activated manually. It will run once every day.\n   \n\n## Maxinst/Update Database Logs\n- The maxinst and update database logs can be retrieved from the admin console pod.\n  - From the OpenShift console, go to the Workloads/Pods menu, select the maxinst pod for your project. Go to terminal tab and cd \"/opt/IBM/SMP/maximo/tools/log/\"  directory to view logs. \n    ","fileAbsolutePath":"/home/travis/build/maximo/manage-playbook/src/pages/upgrade/planning/logging.mdx"}}},"staticQueryHashes":["1054721580","1054721580","1364590287","2102389209","2102389209","2456312558","2746626797","2746626797","3018647132","3018647132","3037994772","3037994772","768070550"]}